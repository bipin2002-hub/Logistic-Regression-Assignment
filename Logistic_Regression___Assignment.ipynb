{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression | Assignment"
      ],
      "metadata": {
        "id": "4OlqQQZLN__U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1:  What is Logistic Regression, and how does it differ from Linear\n",
        "Regression?**"
      ],
      "metadata": {
        "id": "G65UKNhGN-tX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:-** **Logistic Regression** is a supervised machine learning algorithm primarily used for predicting categorical outcomes, especially binary classes (such as yes/no, 0/1) by estimating the probability that an observation belongs to a certain class. It differs from Linear Regression in both its purpose and mathematical formulation: linear regression predicts continuous values, while logistic regression predicts probabilities for discrete classes.\n",
        "\n",
        "**Logistic Regression:**-\n",
        "Logistic regression estimates the probability of a categorical event, usually binary, occurring based on independent variables.\n",
        "\n",
        "It uses a logistic (sigmoid) function to transform the output of a linear combination of input features into a value between 0 and 1, representing probability.\n",
        "\n",
        "The logistic regression equation is:-\n",
        "\n",
        "       y(x)= e^(a0+a1x1+a2x2+⋯+aixi)/1+e^(a0+a1x1+a2x2+⋯+aixi)\n",
        "\n",
        " where y(x)is the probability estimation.\n"
      ],
      "metadata": {
        "id": "EhU6I2hkOUTr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2: Explain the role of the Sigmoid function in Logistic Regression.**"
      ],
      "metadata": {
        "id": "qgCF1SPTQzXf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:-** The sigmoid function is central to logistic regression because it converts the linear combination of input features into a probability value between 0 and 1, enabling meaningful classification for binary outcomes.\n",
        "\n",
        "What the Sigmoid Function Does\n",
        "\n",
        "The sigmoid function has the formula:\n",
        "\n",
        "           σ(z)= 1/1+e^−z\n",
        "\n",
        "where z is the output of the linear equation (log-odds) computed from input features and model parameters.\n",
        "\n",
        "The output is always between 0 and 1, making it ideal for representing probabilities.\n",
        "\n",
        "If z is very large and positive, σ(z) approaches 1; ifz is very large and negative,σ(z) approaches 0; when z=0\n",
        ", σ(z)=0.5.\n",
        "\n",
        "**Role of the Sigmoid function in Logistic Regression.**\n",
        "\n",
        ">1. Logistic regression uses the sigmoid function to translate potentially unbounded real values (from the linear equation) into a valid probability range.\n",
        "\n",
        ">2. This probability can then be thresholded (typically at 0.5) to classify an observation as class 0 or 1.\n",
        "\n",
        ">3. The sigmoid’s S-shaped curve ensures small changes near the threshold (0.5) cause strong changes in class assignment, improving model interpretability for classification tasks.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-dlxhDkMQ4XN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3: What is Regularization in Logistic Regression and why is it needed?**"
      ],
      "metadata": {
        "id": "APVqjyFIThti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:-** **Regularization in logistic regression** is a technique for penalizing model complexity to prevent overfitting and improve the ability to generalize predictions to unseen data.\n",
        "Regularization modifies the loss function by adding a penalty term based on the magnitude of model coefficients.\n",
        "\n",
        "**The two most common types are:**\n",
        "\n",
        "**L1 regularization (Lasso):** Adds the sum of absolute values of coefficients as a penalty, which can reduce some coefficients entirely to zero, effectively performing feature selection.\n",
        "\n",
        "**L2 regularization (Ridge):** Adds the sum of squared values of coefficients as a penalty, shrinking them toward zero but not exactly to zero.\n",
        "\n",
        "**Needs of Regularization:-**\n",
        "\n",
        ">1.Prevents overfitting: Without regularization, logistic regression models can learn noise and idiosyncrasies of the training data, resulting in poor performance on new data.\n",
        "\n",
        ">2.Improves generalizability: By constraining excessively large coefficient weights, the model focuses on more substantial patterns and avoids memorizing the training set.\n",
        "\n",
        ">3.Handles multicollinearity: Regularization techniques reduce the magnitude of correlated predictors, stabilizing model estimates and making coefficients more interpretable.\n",
        "\n",
        ">4.Balances bias-variance: Regularization increases bias slightly, but drastically lowers variance—the main culprit behind overfitting.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W12wE9xrTnQd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4: What are some common evaluation metrics for classification models, and\n",
        "why are they important?**"
      ],
      "metadata": {
        "id": "RvWV4ehPV2oP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:-** Common evaluation metrics for classification models include accuracy, precision, recall, F1 score, confusion matrix, and AUC-ROC. These metrics are crucial for understanding model performance beyond simple correctness, especially when data is imbalanced or when different types of errors carry different consequences.\n",
        "\n",
        "**Key Classification Metrics:-**\n",
        "\n",
        "**Accuracy:** Measures the proportion of correctly classified instances among all instances. Useful as a general measure, but can be misleading with imbalanced classes.\n",
        "\n",
        "**Precision:** Indicates how many predicted positives are true positives, important when the cost of false positives is high (e.g., disease diagnosis).\n",
        "\n",
        "**Recall:** Tells how many actual positives were correctly identified by the model. Crucial when missing a positive instance has a high cost (e.g., fraud detection).\n",
        "\n",
        "**F1 Score:** Harmonic mean of precision and recall. Provides a balance between precision and recall, especially useful when classes are imbalanced.\n",
        "\n",
        "**Confusion Matrix:** Tabular representation of actual vs. predicted classifications, showing true positives, false positives, true negatives, and false negatives. Offers deeper insight into model performance across all outcomes.\n",
        "\n",
        "**AUC-ROC:** Area Under the Receiver Operating Characteristic Curve reflects the model's ability to distinguish between classes across thresholds. Valuable for interpreting model ranking and robustness, independent of a single threshold.\n",
        "\n",
        "**Importance of These Metrics:-**\n",
        "\n",
        ">1. Metrics like precision and recall help pinpoint weaknesses, such as a model with high accuracy but poor recall for minority classes.\n",
        "\n",
        ">2. Choosing appropriate metrics prevents misleading evaluation and aligns performance measurement with business or scientific goals (for example, maximizing recall in cancer screening; maximizing precision in spam detection).\n",
        "\n",
        ">3. These metrics guide model selection, hyperparameter tuning, and deployment decisions to optimize real-world outcomes."
      ],
      "metadata": {
        "id": "JOVRZ-O3WHbA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame,\n",
        "splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "(Use Dataset from sklearn package)**"
      ],
      "metadata": {
        "id": "KzXY1MyvXQcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset from scikit-learn\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data,columns=data.feature_names)\n",
        "df[\"target\"]=data.target\n",
        "\n",
        "# Split into features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split into train test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# Logistic Regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5ehV2eQXVK2",
        "outputId": "9157fe19-8280-4c9d-856a-9e944157cfd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6:  Write a Python program to train a Logistic Regression model using L2\n",
        "regularization (Ridge) and print the model coefficients and accuracy.**"
      ],
      "metadata": {
        "id": "mDd_Osx7ZWHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load iris dataset\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data,columns=data.feature_names)\n",
        "df[\"target\"]=data.target\n",
        "\n",
        "# Features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# Create and train logistic regression model with L2 regularization (default penalty='l2')\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(penalty='l2', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and measure accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Get model coefficients and intercept\n",
        "coefficients = model.coef_\n",
        "intercept = model.intercept_\n",
        "\n",
        "# Print results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Coefficients:\", coefficients)\n",
        "\n",
        "print(\"Intercept:\", intercept)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU0XKkZcPao4",
        "outputId": "6ea2abe9-64c5-4e57-dddc-c579c38e76cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9666666666666667\n",
            "Coefficients: [[-0.43171259  0.82344651 -2.35119244 -0.96938012]\n",
            " [ 0.61818491 -0.42815386 -0.20595953 -0.82952283]\n",
            " [-0.18647232 -0.39529265  2.55715197  1.79890295]]\n",
            "Intercept: [  9.49111756   1.6376074  -11.12872496]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 7: Write a Python program to train a Logistic Regression model for multiclass\n",
        "classification using multi_class='ovr' and print the classification report.\n",
        "(Use Dataset from sklearn package)**"
      ],
      "metadata": {
        "id": "eu1AxnuUbLey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load iris dataset\n",
        "data= load_iris()\n",
        "df = pd.DataFrame(data.data,columns=data.feature_names)\n",
        "df[\"target\"]=data.target\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# Train Logistic Regression model with one-vs-rest strategy\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(multi_class='ovr', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print classification report\n",
        "from sklearn.metrics import classification_report\n",
        "classification_report = classification_report(y_test,y_pred)\n",
        "print(classification_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZR2uwC4bQvC",
        "outputId": "d7f9943c-3171-46aa-9504-6b10ae24cb41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        11\n",
            "           1       1.00      0.69      0.82        13\n",
            "           2       0.60      1.00      0.75         6\n",
            "\n",
            "    accuracy                           0.87        30\n",
            "   macro avg       0.87      0.90      0.86        30\n",
            "weighted avg       0.92      0.87      0.87        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 8: Write a Python program to apply GridSearchCV to tune C and penalty\n",
        "hyperparameters for Logistic Regression and print the best parameters and validation\n",
        "accuracy.**"
      ],
      "metadata": {
        "id": "6OtXyQH7dUzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load iris dataset\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data,columns=data.feature_names)\n",
        "df[\"target\"]=data.target\n",
        "\n",
        "# Features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split into train and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# Define the logistic regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(max_iter=200, solver='liblinear')\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# Setup GridSearchCV with 5-fold cross-validation\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit GridSearchCV to training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Obtain best parameters and accuracy on validation set\n",
        "best_params = grid_search.best_params_\n",
        "y_pred = grid_search.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "val_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Validation Accuracy:\", val_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9aGbdghdlMq",
        "outputId": "5c236659-5a1f-4263-8a12-9e431881b71e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l2'}\n",
            "Validation Accuracy: 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 9: Write a Python program to standardize the features before training Logistic\n",
        "Regression and compare the model's accuracy with and without scaling.**"
      ],
      "metadata": {
        "id": "GI_iAhs7ffrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load iris dataset\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df[\"target\"] = iris.target  # Correct assignment to df, not undefined 'data'\n",
        "\n",
        "# Features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
        "\n",
        "# Train logistic regression without scaling\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)  # fixed variable name to X_train_scaled\n",
        "X_test_scaled = scaler.transform(X_test)  # fixed variable name to X_test_scaled\n",
        "\n",
        "# Train logistic regression with scaling\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model.predict(X_test_scaled)  # use X_test_scaled for prediction\n",
        "accuracy_scaling = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(\"Accuracy without scaling:\", accuracy_no_scaling)\n",
        "print(\"Accuracy with scaling:\", accuracy_scaling)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yod_fSvTfnYt",
        "outputId": "d1d965e0-36f4-43a9-f220-68794ceebb8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.9777777777777777\n",
            "Accuracy with scaling: 0.9555555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10: Imagine you are working at an e-commerce company that wants to\n",
        "predict which customers will respond to a marketing campaign. Given an imbalanced\n",
        "dataset (only 5% of customers respond), describe the approach you’d take to build a\n",
        "Logistic Regression model — including data handling, feature scaling, balancing\n",
        "classes, hyperparameter tuning, and evaluating the model for this real-world business**"
      ],
      "metadata": {
        "id": "eqTPRv67kLPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Step 1: Simulate imbalanced dataset (5% positive class)\n",
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_samples=10000, n_features=20, n_classes=2,\n",
        "                           weights=[0.95, 0.05], flip_y=0, random_state=1)\n",
        "\n",
        "# Step 2: Split into training and testing sets with stratification\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=1)\n",
        "\n",
        "# Step 3: Apply SMOTE to balance training data\n",
        "smote = SMOTE(random_state=1)\n",
        "X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Step 4: Feature scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_bal_scaled = scaler.fit_transform(X_train_bal)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 5: Logistic Regression with hyperparameter tuning and class weights\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']  # 'liblinear' supports both l1 and l2 penalties\n",
        "}\n",
        "\n",
        "logreg = LogisticRegression(class_weight='balanced', max_iter=500)\n",
        "\n",
        "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "grid_search.fit(X_train_bal_scaled, y_train_bal)\n",
        "\n",
        "# Step 6: Evaluation on test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "y_pred_prob = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred_prob))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEhaSvnLkVKc",
        "outputId": "1b583869-293d-4cf0-935a-a33708782ab0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.92      0.95      2850\n",
            "           1       0.36      0.84      0.50       150\n",
            "\n",
            "    accuracy                           0.92      3000\n",
            "   macro avg       0.67      0.88      0.73      3000\n",
            "weighted avg       0.96      0.92      0.93      3000\n",
            "\n",
            "ROC AUC Score: 0.933008187134503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "U-LVPATwPZZV"
      }
    }
  ]
}